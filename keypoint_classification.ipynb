{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0_1</th>\n",
       "      <th>1</th>\n",
       "      <th>1_1</th>\n",
       "      <th>2</th>\n",
       "      <th>2_1</th>\n",
       "      <th>3</th>\n",
       "      <th>3_1</th>\n",
       "      <th>4</th>\n",
       "      <th>4_1</th>\n",
       "      <th>...</th>\n",
       "      <th>16_1</th>\n",
       "      <th>17</th>\n",
       "      <th>17_1</th>\n",
       "      <th>18</th>\n",
       "      <th>18_1</th>\n",
       "      <th>19</th>\n",
       "      <th>19_1</th>\n",
       "      <th>label</th>\n",
       "      <th>20</th>\n",
       "      <th>20_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.457428</td>\n",
       "      <td>0.583321</td>\n",
       "      <td>0.570786</td>\n",
       "      <td>0.503428</td>\n",
       "      <td>0.640131</td>\n",
       "      <td>0.373976</td>\n",
       "      <td>0.651734</td>\n",
       "      <td>0.264575</td>\n",
       "      <td>0.634491</td>\n",
       "      <td>0.179894</td>\n",
       "      <td>...</td>\n",
       "      <td>0.472125</td>\n",
       "      <td>0.325685</td>\n",
       "      <td>0.335119</td>\n",
       "      <td>0.391186</td>\n",
       "      <td>0.321072</td>\n",
       "      <td>0.404947</td>\n",
       "      <td>0.404261</td>\n",
       "      <td>A</td>\n",
       "      <td>0.403822</td>\n",
       "      <td>0.457566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.491985</td>\n",
       "      <td>0.613174</td>\n",
       "      <td>0.606477</td>\n",
       "      <td>0.536362</td>\n",
       "      <td>0.676951</td>\n",
       "      <td>0.406153</td>\n",
       "      <td>0.690357</td>\n",
       "      <td>0.291870</td>\n",
       "      <td>0.674907</td>\n",
       "      <td>0.209456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506045</td>\n",
       "      <td>0.358678</td>\n",
       "      <td>0.350373</td>\n",
       "      <td>0.437198</td>\n",
       "      <td>0.361405</td>\n",
       "      <td>0.449585</td>\n",
       "      <td>0.447797</td>\n",
       "      <td>A</td>\n",
       "      <td>0.444951</td>\n",
       "      <td>0.501605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.583805</td>\n",
       "      <td>0.687606</td>\n",
       "      <td>0.708179</td>\n",
       "      <td>0.634471</td>\n",
       "      <td>0.776888</td>\n",
       "      <td>0.506354</td>\n",
       "      <td>0.787617</td>\n",
       "      <td>0.383429</td>\n",
       "      <td>0.812475</td>\n",
       "      <td>0.285312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.671530</td>\n",
       "      <td>0.423932</td>\n",
       "      <td>0.480300</td>\n",
       "      <td>0.436632</td>\n",
       "      <td>0.482285</td>\n",
       "      <td>0.456371</td>\n",
       "      <td>0.586887</td>\n",
       "      <td>A</td>\n",
       "      <td>0.476671</td>\n",
       "      <td>0.648893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.723598</td>\n",
       "      <td>0.674288</td>\n",
       "      <td>0.796444</td>\n",
       "      <td>0.618316</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.513981</td>\n",
       "      <td>0.862209</td>\n",
       "      <td>0.426482</td>\n",
       "      <td>0.858674</td>\n",
       "      <td>0.356800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.567408</td>\n",
       "      <td>0.628164</td>\n",
       "      <td>0.489217</td>\n",
       "      <td>0.623643</td>\n",
       "      <td>0.453718</td>\n",
       "      <td>0.630732</td>\n",
       "      <td>0.510247</td>\n",
       "      <td>A</td>\n",
       "      <td>0.640717</td>\n",
       "      <td>0.556273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.695232</td>\n",
       "      <td>0.710189</td>\n",
       "      <td>0.775316</td>\n",
       "      <td>0.622683</td>\n",
       "      <td>0.827593</td>\n",
       "      <td>0.521930</td>\n",
       "      <td>0.842571</td>\n",
       "      <td>0.429177</td>\n",
       "      <td>0.849023</td>\n",
       "      <td>0.354402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573719</td>\n",
       "      <td>0.611416</td>\n",
       "      <td>0.496050</td>\n",
       "      <td>0.611099</td>\n",
       "      <td>0.452895</td>\n",
       "      <td>0.624936</td>\n",
       "      <td>0.509147</td>\n",
       "      <td>A</td>\n",
       "      <td>0.641204</td>\n",
       "      <td>0.559075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0       0_1         1       1_1         2       2_1         3  \\\n",
       "0  0.457428  0.583321  0.570786  0.503428  0.640131  0.373976  0.651734   \n",
       "1  0.491985  0.613174  0.606477  0.536362  0.676951  0.406153  0.690357   \n",
       "2  0.583805  0.687606  0.708179  0.634471  0.776888  0.506354  0.787617   \n",
       "3  0.723598  0.674288  0.796444  0.618316  0.847458  0.513981  0.862209   \n",
       "4  0.695232  0.710189  0.775316  0.622683  0.827593  0.521930  0.842571   \n",
       "\n",
       "        3_1         4       4_1  ...      16_1        17      17_1        18  \\\n",
       "0  0.264575  0.634491  0.179894  ...  0.472125  0.325685  0.335119  0.391186   \n",
       "1  0.291870  0.674907  0.209456  ...  0.506045  0.358678  0.350373  0.437198   \n",
       "2  0.383429  0.812475  0.285312  ...  0.671530  0.423932  0.480300  0.436632   \n",
       "3  0.426482  0.858674  0.356800  ...  0.567408  0.628164  0.489217  0.623643   \n",
       "4  0.429177  0.849023  0.354402  ...  0.573719  0.611416  0.496050  0.611099   \n",
       "\n",
       "       18_1        19      19_1  label        20      20_1  \n",
       "0  0.321072  0.404947  0.404261      A  0.403822  0.457566  \n",
       "1  0.361405  0.449585  0.447797      A  0.444951  0.501605  \n",
       "2  0.482285  0.456371  0.586887      A  0.476671  0.648893  \n",
       "3  0.453718  0.630732  0.510247      A  0.640717  0.556273  \n",
       "4  0.452895  0.624936  0.509147      A  0.641204  0.559075  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "\n",
    "seed = 42\n",
    "data_import = pd.read_csv(\"keypoints.csv\", index_col=0)\n",
    "data_import.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = data_import.drop(\"label\", axis=1)\n",
    "y_data_raw = data_import['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "y_data = label_encoder.fit_transform(y_data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = data_import.label.nunique()\n",
    "input_shape = X_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 50)                2150      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 50)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 40)                2040      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 40)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 30)                1230      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 28)                868       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,288\n",
      "Trainable params: 6,288\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input((input_shape)),\n",
    "    keras.layers.Dense(50, activation ='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(40, activation = 'relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(30, activation = 'relu'),\n",
    "    keras.layers.Dense(num_classes, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Callbacks\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"keypoint_classifier.h5\", save_best_only=True)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_loss\" , patience=10)\n",
    "\n",
    "# Model Compilation\n",
    "model.compile(optimizer='adam', \n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "19/19 [==============================] - 3s 55ms/step - loss: 3.3352 - accuracy: 0.0482 - val_loss: 3.3089 - val_accuracy: 0.0309\n",
      "Epoch 2/500\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 3.3041 - accuracy: 0.0516 - val_loss: 3.2819 - val_accuracy: 0.0893\n",
      "Epoch 3/500\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 3.2781 - accuracy: 0.0620 - val_loss: 3.2333 - val_accuracy: 0.1271\n",
      "Epoch 4/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 3.2265 - accuracy: 0.0947 - val_loss: 3.1651 - val_accuracy: 0.1512\n",
      "Epoch 5/500\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 3.1646 - accuracy: 0.1170 - val_loss: 3.0599 - val_accuracy: 0.1375\n",
      "Epoch 6/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 3.0853 - accuracy: 0.1403 - val_loss: 2.9379 - val_accuracy: 0.1512\n",
      "Epoch 7/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 2.9645 - accuracy: 0.1463 - val_loss: 2.7675 - val_accuracy: 0.1753\n",
      "Epoch 8/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 2.8469 - accuracy: 0.1919 - val_loss: 2.6258 - val_accuracy: 0.2715\n",
      "Epoch 9/500\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 2.7089 - accuracy: 0.2255 - val_loss: 2.4612 - val_accuracy: 0.4296\n",
      "Epoch 10/500\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 2.5352 - accuracy: 0.2745 - val_loss: 2.2787 - val_accuracy: 0.4227\n",
      "Epoch 11/500\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 2.3862 - accuracy: 0.2831 - val_loss: 2.0981 - val_accuracy: 0.4330\n",
      "Epoch 12/500\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 2.2048 - accuracy: 0.3494 - val_loss: 1.9505 - val_accuracy: 0.5258\n",
      "Epoch 13/500\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 2.0822 - accuracy: 0.3847 - val_loss: 1.7945 - val_accuracy: 0.5601\n",
      "Epoch 14/500\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 1.9461 - accuracy: 0.4294 - val_loss: 1.6682 - val_accuracy: 0.5739\n",
      "Epoch 15/500\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 1.8136 - accuracy: 0.4518 - val_loss: 1.5467 - val_accuracy: 0.6392\n",
      "Epoch 16/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 1.7187 - accuracy: 0.4759 - val_loss: 1.4184 - val_accuracy: 0.6529\n",
      "Epoch 17/500\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 1.6276 - accuracy: 0.4983 - val_loss: 1.3467 - val_accuracy: 0.7045\n",
      "Epoch 18/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 1.5377 - accuracy: 0.5318 - val_loss: 1.2704 - val_accuracy: 0.7216\n",
      "Epoch 19/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 1.4799 - accuracy: 0.5336 - val_loss: 1.1794 - val_accuracy: 0.7113\n",
      "Epoch 20/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 1.3752 - accuracy: 0.5706 - val_loss: 1.1106 - val_accuracy: 0.7320\n",
      "Epoch 21/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 1.3538 - accuracy: 0.5800 - val_loss: 1.0648 - val_accuracy: 0.7457\n",
      "Epoch 22/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 1.3062 - accuracy: 0.5843 - val_loss: 1.0077 - val_accuracy: 0.8041\n",
      "Epoch 23/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 1.2311 - accuracy: 0.5998 - val_loss: 0.9531 - val_accuracy: 0.8144\n",
      "Epoch 24/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 1.2040 - accuracy: 0.5981 - val_loss: 0.9319 - val_accuracy: 0.8041\n",
      "Epoch 25/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 1.1885 - accuracy: 0.6145 - val_loss: 0.9036 - val_accuracy: 0.8247\n",
      "Epoch 26/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 1.1303 - accuracy: 0.6497 - val_loss: 0.8676 - val_accuracy: 0.8282\n",
      "Epoch 27/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 1.0896 - accuracy: 0.6532 - val_loss: 0.8319 - val_accuracy: 0.8625\n",
      "Epoch 28/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 1.0754 - accuracy: 0.6463 - val_loss: 0.8003 - val_accuracy: 0.8316\n",
      "Epoch 29/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 1.0565 - accuracy: 0.6532 - val_loss: 0.7708 - val_accuracy: 0.8522\n",
      "Epoch 30/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 1.0060 - accuracy: 0.6618 - val_loss: 0.7413 - val_accuracy: 0.8694\n",
      "Epoch 31/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 1.0020 - accuracy: 0.6790 - val_loss: 0.7402 - val_accuracy: 0.8900\n",
      "Epoch 32/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.9337 - accuracy: 0.7108 - val_loss: 0.7079 - val_accuracy: 0.8797\n",
      "Epoch 33/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.9532 - accuracy: 0.6928 - val_loss: 0.6960 - val_accuracy: 0.8763\n",
      "Epoch 34/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.8993 - accuracy: 0.7169 - val_loss: 0.6751 - val_accuracy: 0.8832\n",
      "Epoch 35/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.8638 - accuracy: 0.7143 - val_loss: 0.6424 - val_accuracy: 0.8900\n",
      "Epoch 36/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.8486 - accuracy: 0.7349 - val_loss: 0.6350 - val_accuracy: 0.8866\n",
      "Epoch 37/500\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.8658 - accuracy: 0.7100 - val_loss: 0.6206 - val_accuracy: 0.9175\n",
      "Epoch 38/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.8089 - accuracy: 0.7478 - val_loss: 0.6076 - val_accuracy: 0.9003\n",
      "Epoch 39/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.8238 - accuracy: 0.7375 - val_loss: 0.5989 - val_accuracy: 0.8969\n",
      "Epoch 40/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.8150 - accuracy: 0.7418 - val_loss: 0.5808 - val_accuracy: 0.8969\n",
      "Epoch 41/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.7550 - accuracy: 0.7590 - val_loss: 0.6057 - val_accuracy: 0.9107\n",
      "Epoch 42/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.7559 - accuracy: 0.7504 - val_loss: 0.5755 - val_accuracy: 0.9072\n",
      "Epoch 43/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.7857 - accuracy: 0.7332 - val_loss: 0.5743 - val_accuracy: 0.8900\n",
      "Epoch 44/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.7701 - accuracy: 0.7478 - val_loss: 0.5565 - val_accuracy: 0.8832\n",
      "Epoch 45/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.7029 - accuracy: 0.7806 - val_loss: 0.5429 - val_accuracy: 0.8866\n",
      "Epoch 46/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.7268 - accuracy: 0.7659 - val_loss: 0.5222 - val_accuracy: 0.9072\n",
      "Epoch 47/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.7156 - accuracy: 0.7702 - val_loss: 0.5338 - val_accuracy: 0.9175\n",
      "Epoch 48/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.7280 - accuracy: 0.7590 - val_loss: 0.5286 - val_accuracy: 0.8935\n",
      "Epoch 49/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.7008 - accuracy: 0.7797 - val_loss: 0.5247 - val_accuracy: 0.8935\n",
      "Epoch 50/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.6685 - accuracy: 0.7926 - val_loss: 0.5167 - val_accuracy: 0.8969\n",
      "Epoch 51/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6524 - accuracy: 0.8072 - val_loss: 0.4947 - val_accuracy: 0.9278\n",
      "Epoch 52/500\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.6580 - accuracy: 0.7849 - val_loss: 0.4929 - val_accuracy: 0.9141\n",
      "Epoch 53/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6567 - accuracy: 0.7909 - val_loss: 0.4811 - val_accuracy: 0.9038\n",
      "Epoch 54/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6405 - accuracy: 0.7831 - val_loss: 0.4822 - val_accuracy: 0.9416\n",
      "Epoch 55/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6431 - accuracy: 0.7857 - val_loss: 0.4952 - val_accuracy: 0.8935\n",
      "Epoch 56/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.6314 - accuracy: 0.7900 - val_loss: 0.4870 - val_accuracy: 0.8935\n",
      "Epoch 57/500\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.6137 - accuracy: 0.7969 - val_loss: 0.4841 - val_accuracy: 0.8935\n",
      "Epoch 58/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5909 - accuracy: 0.8244 - val_loss: 0.4625 - val_accuracy: 0.9107\n",
      "Epoch 59/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5982 - accuracy: 0.7986 - val_loss: 0.4560 - val_accuracy: 0.9175\n",
      "Epoch 60/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5561 - accuracy: 0.8279 - val_loss: 0.4585 - val_accuracy: 0.9072\n",
      "Epoch 61/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5897 - accuracy: 0.8098 - val_loss: 0.4664 - val_accuracy: 0.8832\n",
      "Epoch 62/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5593 - accuracy: 0.8158 - val_loss: 0.4545 - val_accuracy: 0.9450\n",
      "Epoch 63/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5716 - accuracy: 0.8262 - val_loss: 0.4406 - val_accuracy: 0.9141\n",
      "Epoch 64/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5676 - accuracy: 0.8184 - val_loss: 0.4405 - val_accuracy: 0.8969\n",
      "Epoch 65/500\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5173 - accuracy: 0.8219 - val_loss: 0.4358 - val_accuracy: 0.9210\n",
      "Epoch 66/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5280 - accuracy: 0.8270 - val_loss: 0.4175 - val_accuracy: 0.9072\n",
      "Epoch 67/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5453 - accuracy: 0.8081 - val_loss: 0.4325 - val_accuracy: 0.9416\n",
      "Epoch 68/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5550 - accuracy: 0.8064 - val_loss: 0.4189 - val_accuracy: 0.9450\n",
      "Epoch 69/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5288 - accuracy: 0.8296 - val_loss: 0.4344 - val_accuracy: 0.9313\n",
      "Epoch 70/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5250 - accuracy: 0.8253 - val_loss: 0.4150 - val_accuracy: 0.9038\n",
      "Epoch 71/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5125 - accuracy: 0.8322 - val_loss: 0.4319 - val_accuracy: 0.9244\n",
      "Epoch 72/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5167 - accuracy: 0.8236 - val_loss: 0.4241 - val_accuracy: 0.9278\n",
      "Epoch 73/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5238 - accuracy: 0.8322 - val_loss: 0.4327 - val_accuracy: 0.9313\n",
      "Epoch 74/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4872 - accuracy: 0.8554 - val_loss: 0.4333 - val_accuracy: 0.9347\n",
      "Epoch 75/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.5044 - accuracy: 0.8348 - val_loss: 0.4083 - val_accuracy: 0.9072\n",
      "Epoch 76/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4925 - accuracy: 0.8287 - val_loss: 0.4136 - val_accuracy: 0.9347\n",
      "Epoch 77/500\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.4642 - accuracy: 0.8425 - val_loss: 0.4079 - val_accuracy: 0.9107\n",
      "Epoch 78/500\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.4956 - accuracy: 0.8262 - val_loss: 0.4011 - val_accuracy: 0.9381\n",
      "Epoch 79/500\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4831 - accuracy: 0.8528 - val_loss: 0.3965 - val_accuracy: 0.9210\n",
      "Epoch 80/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4645 - accuracy: 0.8442 - val_loss: 0.4107 - val_accuracy: 0.9381\n",
      "Epoch 81/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4643 - accuracy: 0.8503 - val_loss: 0.4126 - val_accuracy: 0.9278\n",
      "Epoch 82/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4785 - accuracy: 0.8365 - val_loss: 0.4071 - val_accuracy: 0.9175\n",
      "Epoch 83/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4654 - accuracy: 0.8477 - val_loss: 0.4273 - val_accuracy: 0.9519\n",
      "Epoch 84/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4846 - accuracy: 0.8391 - val_loss: 0.3892 - val_accuracy: 0.9519\n",
      "Epoch 85/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4498 - accuracy: 0.8485 - val_loss: 0.4110 - val_accuracy: 0.9519\n",
      "Epoch 86/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4598 - accuracy: 0.8460 - val_loss: 0.4060 - val_accuracy: 0.9416\n",
      "Epoch 87/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4664 - accuracy: 0.8417 - val_loss: 0.3970 - val_accuracy: 0.9450\n",
      "Epoch 88/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4411 - accuracy: 0.8494 - val_loss: 0.4239 - val_accuracy: 0.9278\n",
      "Epoch 89/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4175 - accuracy: 0.8640 - val_loss: 0.3978 - val_accuracy: 0.9347\n",
      "Epoch 90/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4283 - accuracy: 0.8554 - val_loss: 0.4058 - val_accuracy: 0.9381\n",
      "Epoch 91/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4501 - accuracy: 0.8399 - val_loss: 0.4161 - val_accuracy: 0.9519\n",
      "Epoch 92/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4152 - accuracy: 0.8683 - val_loss: 0.4106 - val_accuracy: 0.9485\n",
      "Epoch 93/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4286 - accuracy: 0.8571 - val_loss: 0.4158 - val_accuracy: 0.9519\n",
      "Epoch 94/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4186 - accuracy: 0.8580 - val_loss: 0.4072 - val_accuracy: 0.9244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2dba38ec8e0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model training\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "            batch_size = 64,\n",
    "            epochs=500,\n",
    "            validation_data = (X_test, y_test),\n",
    "            callbacks = [checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3892 - accuracy: 0.9519\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.38921529054641724, 0.9518900513648987]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading saved model\n",
    "model = keras.models.load_model(\"keypoint_classifier.h5\")\n",
    "\n",
    "# Evaluate\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "True Label: 16\n",
      "ptrdivtion: 16\n"
     ]
    }
   ],
   "source": [
    "# Prediction on random sample\n",
    "\n",
    "import random\n",
    "i = random.randint(0, len(X_data))\n",
    "X = X_data.iloc[i]\n",
    "y = y_data[i]\n",
    "pred = model.predict(np.array([X]))\n",
    "print(\"True Label:\", y)\n",
    "print(\"prediction:\", np.argmax(pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7199ef7af2be396f8272c772dab15d0b8bb336c60216fde39d64c1e2e09d623b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
